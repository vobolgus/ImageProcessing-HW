{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 4749004,
     "sourceType": "datasetVersion",
     "datasetId": 2733586
    }
   ],
   "dockerImageVersionId": 31154,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nfrom PIL import Image\nfrom tempfile import TemporaryDirectory\nimport random \n\n\ncudnn.benchmark = True\nplt.ion()   # interactive mode",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-19T21:05:07.633850Z",
     "iopub.execute_input": "2025-10-19T21:05:07.634058Z",
     "iopub.status.idle": "2025-10-19T21:05:15.476756Z",
     "shell.execute_reply.started": "2025-10-19T21:05:07.634037Z",
     "shell.execute_reply": "2025-10-19T21:05:15.476166Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-25T14:42:37.049198Z",
     "start_time": "2025-10-25T14:42:37.044804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x250e602f470>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "# Fix all random seeds\nseed = 0\ntorch.manual_seed(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\n\n# Worker seeding for dataloader workers\ndef seed_worker(worker_id):\n    # Ensures each worker has the same seed derived from the global seed\n    worker_seed = seed + worker_id\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n    \n# DataLoader setup with fixed generator\ng = torch.Generator()\ng.manual_seed(seed)\nNone",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-19T21:05:15.477386Z",
     "iopub.execute_input": "2025-10-19T21:05:15.477637Z",
     "iopub.status.idle": "2025-10-19T21:05:15.487692Z",
     "shell.execute_reply.started": "2025-10-19T21:05:15.477622Z",
     "shell.execute_reply": "2025-10-19T21:05:15.487228Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-25T14:42:37.968593Z",
     "start_time": "2025-10-25T14:42:37.964004Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": "# Download [data](https://www.kaggle.com/datasets/samuelcortinhas/muffin-vs-chihuahua-image-classification)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        # transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "def rgb_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f).convert('RGBA')\n",
    "        return img.convert('RGB')\n",
    "\n",
    "\n",
    "data_dir = 'data/muffin-vs-chihuahua-image-classification'\n",
    "image_datasets = {\n",
    "    'train': datasets.ImageFolder(os.path.join(data_dir, 'train'), data_transforms['train'], loader=rgb_loader),\n",
    "    'test': datasets.ImageFolder(os.path.join(data_dir, 'test'), data_transforms['test'], loader=rgb_loader)\n",
    "}\n",
    "\n",
    "full_train_dataset = image_datasets['train']\n",
    "\n",
    "# Define the split ratio (e.g., 80% train, 20% validation)\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "\n",
    "# Perform the random split\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    full_train_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=g\n",
    ")\n",
    "\n",
    "train_dataset.dataset.transform = data_transforms['train']\n",
    "val_dataset.dataset.transform = data_transforms['test']\n",
    "image_datasets['train'] = train_dataset\n",
    "image_datasets['val'] = val_dataset\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=4, worker_init_fn=seed_worker,\n",
    "        generator=g,\n",
    "    )\n",
    "    for x in ['train', 'val', 'test']\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "class_names = image_datasets['test'].classes\n",
    "\n",
    "# Calculate the number of images per class in each dataset\n",
    "class_distribution = {}\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_obj = image_datasets[split]\n",
    "    split_class_counts = {class_name: 0 for class_name in class_names}\n",
    "\n",
    "    # If it's a Subset, use its indices to count samples from the underlying dataset\n",
    "    if isinstance(split_obj, torch.utils.data.Subset):\n",
    "        base_dataset = split_obj.dataset\n",
    "        indices = getattr(split_obj, \"indices\", None)\n",
    "        if indices is None:\n",
    "            indices = list(range(len(base_dataset)))\n",
    "        for idx in indices:\n",
    "            _, label = base_dataset.samples[idx]\n",
    "            class_name = class_names[label]\n",
    "            split_class_counts[class_name] += 1\n",
    "    else:\n",
    "        for _, label in split_obj.samples:\n",
    "            class_name = class_names[label]\n",
    "            split_class_counts[class_name] += 1\n",
    "\n",
    "    class_distribution[split] = split_class_counts\n",
    "\n",
    "print(f'Dataset sizes: {dataset_sizes}')\n",
    "print(f'Class names: {class_names}')\n",
    "for split, dist in class_distribution.items():\n",
    "    print(f'{split.capitalize()} class distribution: {dist}')\n",
    "\n",
    "# We want to be able to train our model on an `accelerator <https://pytorch.org/docs/stable/torch.html#accelerators>`__\n",
    "# such as CUDA, MPS, MTIA, or XPU. If the current accelerator is available, we will use it. Otherwise, we use the CPU.\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-19T21:05:15.489046Z",
     "iopub.execute_input": "2025-10-19T21:05:15.489319Z",
     "iopub.status.idle": "2025-10-19T21:05:21.177186Z",
     "shell.execute_reply.started": "2025-10-19T21:05:15.489296Z",
     "shell.execute_reply": "2025-10-19T21:05:21.176530Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-25T14:42:39.147531Z",
     "start_time": "2025-10-25T14:42:39.110954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: {'train': 3786, 'val': 947, 'test': 1184}\n",
      "Class names: ['chihuahua', 'muffin']\n",
      "Train class distribution: {'chihuahua': 2052, 'muffin': 1734}\n",
      "Val class distribution: {'chihuahua': 507, 'muffin': 440}\n",
      "Test class distribution: {'chihuahua': 640, 'muffin': 544}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": "# Visualise data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "# out = torchvision.utils.make_grid(inputs[:6])\n",
    "\n",
    "# imshow(out, title=[class_names[x] for x in classes[:6]])"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-19T21:05:21.177886Z",
     "iopub.execute_input": "2025-10-19T21:05:21.178224Z",
     "iopub.status.idle": "2025-10-19T21:05:22.703013Z",
     "shell.execute_reply.started": "2025-10-19T21:05:21.178206Z",
     "shell.execute_reply": "2025-10-19T21:05:22.702417Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    # Create a temporary directory to save training checkpoints\n    with TemporaryDirectory() as tempdir:\n        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n\n        torch.save(model.state_dict(), best_model_params_path)\n        best_acc = 0.0\n\n        for epoch in range(num_epochs):\n            print(f'Epoch {epoch}/{num_epochs - 1}')\n            print('-' * 10)\n\n            # Each epoch has a training and validation phase\n            for phase in ['train', 'val']:\n                if phase == 'train':\n                    model.train()  # Set model to training mode\n                else:\n                    model.eval()   # Set model to evaluate mode\n\n                running_loss = 0.0\n                running_corrects = 0\n\n                # Iterate over data.\n                for inputs, labels in dataloaders[phase]:\n                    inputs = inputs.to(device)\n                    labels = labels.to(device)\n\n                    # zero the parameter gradients\n                    optimizer.zero_grad()\n\n                    # forward\n                    # track history if only in train\n                    with torch.set_grad_enabled(phase == 'train'):\n                        outputs = model(inputs)\n                        _, preds = torch.max(outputs, 1)\n                        loss = criterion(outputs, labels)\n\n                        # backward + optimize only if in training phase\n                        if phase == 'train':\n                            loss.backward()\n                            optimizer.step()\n\n                    # statistics\n                    running_loss += loss.item() * inputs.size(0)\n                    running_corrects += torch.sum(preds == labels.data)\n                if phase == 'train' and scheduler:\n                    scheduler.step()\n\n                epoch_loss = running_loss / dataset_sizes[phase]\n                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n                # deep copy the model\n                if phase == 'val' and epoch_acc > best_acc:\n                    best_acc = epoch_acc\n                    torch.save(model.state_dict(), best_model_params_path)\n\n            print()\n\n        time_elapsed = time.time() - since\n        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n        print(f'Best Val Acc: {best_acc:4f}')\n\n        # load best model weights\n        model.load_state_dict(torch.load(best_model_params_path, weights_only=True))\n    return model",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-19T21:05:22.703897Z",
     "iopub.execute_input": "2025-10-19T21:05:22.704181Z",
     "iopub.status.idle": "2025-10-19T21:05:22.712749Z",
     "shell.execute_reply.started": "2025-10-19T21:05:22.704152Z",
     "shell.execute_reply": "2025-10-19T21:05:22.712177Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-25T14:42:44.928128Z",
     "start_time": "2025-10-25T14:42:44.923097Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": "# Training the model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def evaluate_best_model(model):\n    model.eval()\n    \n    running_corrects = 0\n    \n    if 'test' not in dataloaders:\n        return 0.0\n\n    print(\"-\" * 10)\n    print(\"Starting Final Test Evaluation...\")\n    \n    with torch.no_grad():\n        for inputs, labels in dataloaders['test']:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            running_corrects += torch.sum(preds == labels.data)\n\n    test_acc = running_corrects.double() / dataset_sizes['test']\n    print(f'Final Test Acc with Best Model: {test_acc:.4f}')\n    print(\"-\" * 10)\n    \n    return test_acc",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-19T21:05:22.713523Z",
     "iopub.execute_input": "2025-10-19T21:05:22.713807Z",
     "iopub.status.idle": "2025-10-19T21:05:22.733583Z",
     "shell.execute_reply.started": "2025-10-19T21:05:22.713785Z",
     "shell.execute_reply": "2025-10-19T21:05:22.732890Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-25T14:42:48.535930Z",
     "start_time": "2025-10-25T14:42:48.531968Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": "# Visualizing the model predictions",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['test']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images//2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title(f'predicted: {class_names[preds[j]]}')\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-19T21:05:22.734143Z",
     "iopub.execute_input": "2025-10-19T21:05:22.734338Z",
     "iopub.status.idle": "2025-10-19T21:05:22.748257Z",
     "shell.execute_reply.started": "2025-10-19T21:05:22.734324Z",
     "shell.execute_reply": "2025-10-19T21:05:22.747614Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-25T14:42:51.431870Z",
     "start_time": "2025-10-25T14:42:51.427890Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": "def get_params_number(model):\n    num_params = sum(p.numel() for p in model.parameters())\n    num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    \n    print(f\"Total parameters: {num_params:,}\")\n    print(f\"Trainable parameters: {num_trainable:,}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-19T21:05:22.749104Z",
     "iopub.execute_input": "2025-10-19T21:05:22.749365Z",
     "iopub.status.idle": "2025-10-19T21:05:22.766783Z",
     "shell.execute_reply.started": "2025-10-19T21:05:22.749348Z",
     "shell.execute_reply": "2025-10-19T21:05:22.766016Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-25T14:42:54.311062Z",
     "start_time": "2025-10-25T14:42:54.307800Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": "# Resnet152",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "learning_rate = 1e-3 \nnum_epochs = 20\n\nmodel_resnet = models.resnet152(weights='IMAGENET1K_V1')\nnum_ftrs = model_resnet.fc.in_features\nmodel_resnet.fc = nn.Linear(num_ftrs, 2)\n\nmodel_resnet = model_resnet.to(device)\n\noptimizer_resnet = optim.AdamW(model_resnet.parameters(), lr=learning_rate)\nT_max = num_epochs  \nexp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer_resnet, T_max=T_max)\n\ncriterion = nn.CrossEntropyLoss()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-19T21:05:22.768666Z",
     "iopub.execute_input": "2025-10-19T21:05:22.768843Z",
     "iopub.status.idle": "2025-10-19T21:05:25.516665Z",
     "shell.execute_reply.started": "2025-10-19T21:05:22.768820Z",
     "shell.execute_reply": "2025-10-19T21:05:25.516085Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-25T14:43:14.247562Z",
     "start_time": "2025-10-25T14:42:56.370554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to C:\\Users\\ogurc/.cache\\torch\\hub\\checkpoints\\resnet152-394f9c45.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230M/230M [00:16<00:00, 14.6MB/s] \n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": "get_params_number(model_resnet)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-19T21:05:25.517320Z",
     "iopub.execute_input": "2025-10-19T21:05:25.517495Z",
     "iopub.status.idle": "2025-10-19T21:05:25.523611Z",
     "shell.execute_reply.started": "2025-10-19T21:05:25.517482Z",
     "shell.execute_reply": "2025-10-19T21:05:25.522676Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-25T14:43:22.299852Z",
     "start_time": "2025-10-25T14:43:22.294754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 58,147,906\n",
      "Trainable parameters: 58,147,906\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": "model_resnet = train_model(model_resnet, criterion, optimizer_resnet, exp_lr_scheduler,\n                       num_epochs=num_epochs)\nevaluate_best_model(model_resnet)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-19T21:05:25.524430Z",
     "iopub.execute_input": "2025-10-19T21:05:25.524702Z",
     "iopub.status.idle": "2025-10-19T21:40:17.736338Z",
     "shell.execute_reply.started": "2025-10-19T21:05:25.524687Z",
     "shell.execute_reply": "2025-10-19T21:40:17.735585Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-25T14:44:44.050510700Z",
     "start_time": "2025-10-25T14:43:23.243288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "visualize_model(model_resnet)\n\nplt.ioff()\nplt.show()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-19T21:40:17.740865Z",
     "iopub.execute_input": "2025-10-19T21:40:17.741071Z",
     "iopub.status.idle": "2025-10-19T21:40:20.097571Z",
     "shell.execute_reply.started": "2025-10-19T21:40:17.741051Z",
     "shell.execute_reply": "2025-10-19T21:40:20.096848Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Vit_b_16",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "learning_rate = 1e-3\nnum_epochs = 20\n\nmodel_vit = models.vit_b_16(weights='IMAGENET1K_V1')\nnum_ftrs = model_vit.heads.head.in_features\nmodel_vit.heads.head = nn.Linear(num_ftrs, 2)\n\nmodel_vit = model_vit.to(device)\n\noptimizer_vit = optim.AdamW(model_vit.parameters(), lr=learning_rate)\nT_max = num_epochs  \nexp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer_vit, T_max=T_max)\n\nget_params_number(model_vit)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-19T21:40:20.098596Z",
     "iopub.execute_input": "2025-10-19T21:40:20.098902Z",
     "iopub.status.idle": "2025-10-19T21:40:23.826935Z",
     "shell.execute_reply.started": "2025-10-19T21:40:20.098885Z",
     "shell.execute_reply": "2025-10-19T21:40:23.826146Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "model_vit = train_model(model_vit, criterion, optimizer_vit, exp_lr_scheduler,\n                       num_epochs=num_epochs)\n\nevaluate_best_model(model_vit)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-19T21:40:23.827810Z",
     "iopub.execute_input": "2025-10-19T21:40:23.828082Z",
     "iopub.status.idle": "2025-10-19T22:32:14.882667Z",
     "shell.execute_reply.started": "2025-10-19T21:40:23.828056Z",
     "shell.execute_reply": "2025-10-19T22:32:14.881758Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "visualize_model(model_vit)\n\nplt.ioff()\nplt.show()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-19T22:32:14.883839Z",
     "iopub.execute_input": "2025-10-19T22:32:14.884251Z",
     "iopub.status.idle": "2025-10-19T22:32:17.145177Z",
     "shell.execute_reply.started": "2025-10-19T22:32:14.884228Z",
     "shell.execute_reply": "2025-10-19T22:32:17.144502Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Swin_s",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "model_swin = models.swin_t(weights='IMAGENET1K_V1')\n",
    "\n",
    "num_ftrs = model_swin.head.in_features\n",
    "model_swin.head = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_swin = model_swin.to(device)\n",
    "\n",
    "optimizer_swin = optim.AdamW(model_swin.parameters(), lr=learning_rate)\n",
    "T_max = num_epochs  \n",
    "exp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer_swin, T_max=T_max)\n",
    "\n",
    "get_params_number(model_swin)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-19T22:32:17.150716Z",
     "iopub.execute_input": "2025-10-19T22:32:17.150979Z",
     "iopub.status.idle": "2025-10-19T22:32:19.660793Z",
     "shell.execute_reply.started": "2025-10-19T22:32:17.150960Z",
     "shell.execute_reply": "2025-10-19T22:32:19.659988Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "model_swin = train_model(model_swin, criterion, optimizer_swin, exp_lr_scheduler,\n                       num_epochs=num_epochs)\n\nevaluate_best_model(model_swin)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-19T22:32:19.661737Z",
     "iopub.execute_input": "2025-10-19T22:32:19.661965Z",
     "iopub.status.idle": "2025-10-19T23:06:56.982507Z",
     "shell.execute_reply.started": "2025-10-19T22:32:19.661948Z",
     "shell.execute_reply": "2025-10-19T23:06:56.981584Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "visualize_model(model_swin)\n\nplt.ioff()\nplt.show()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-19T23:06:56.983730Z",
     "iopub.execute_input": "2025-10-19T23:06:56.984443Z",
     "iopub.status.idle": "2025-10-19T23:06:59.423525Z",
     "shell.execute_reply.started": "2025-10-19T23:06:56.984420Z",
     "shell.execute_reply": "2025-10-19T23:06:59.422804Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
